@inproceedings{damasPrincipalTypeschemesFunctional1982,
  title     = {Principal Type-Schemes for Functional Programs},
  booktitle = {Proceedings of the 9th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author    = {Damas, Luis and Milner, Robin},
  date      = {1982-01-25},
  series    = {{{POPL}} '82},
  pages     = {207--212},
  publisher = {Association for Computing Machinery},
  location  = {New York, NY, USA},
  doi       = {10.1145/582153.582176},
  url       = {https://dl.acm.org/doi/10.1145/582153.582176},
  urldate   = {2025-02-07},
  isbn      = {978-0-89791-065-1}
}

@article{damasTypeAssignmentProgramming1984,
  title      = {Type Assignment in Programming Languages},
  author     = {Damas, Luis},
  date       = {1984},
  publisher  = {The University of Edinburgh},
  url        = {https://era.ed.ac.uk/handle/1842/13555},
  urldate    = {2025-02-07},
  langid     = {english},
  annotation = {Accepted: 2016-01-20T10:03:21Z}
}

@online{EfficientInsightfulGeneralization2022,
  title   = {Efficient and {{Insightful Generalization}}},
  date    = {2022-01-09},
  url     = {https://okmij.org/ftp/ML/generalization.html},
  urldate = {2025-03-07},
  file    = {/home/eneagiger/Zotero/storage/3ZHTU2FA/generalization.html}
}


@article{milnerTheoryTypePolymorphism1978,
  title        = {A Theory of Type Polymorphism in Programming},
  author       = {Milner, Robin},
  date         = {1978-12-01},
  journaltitle = {Journal of Computer and System Sciences},
  shortjournal = {Journal of Computer and System Sciences},
  volume       = {17},
  number       = {3},
  pages        = {348--375},
  issn         = {0022-0000},
  doi          = {10.1016/0022-0000(78)90014-4},
  url          = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
  urldate      = {2025-02-05},
  abstract     = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.}
}

@inproceedings{prattTopOperatorPrecedence1973,
  title     = {Top down Operator Precedence},
  booktitle = {Proceedings of the 1st Annual {{ACM SIGACT-SIGPLAN}} Symposium on {{Principles}} of Programming Languages},
  author    = {Pratt, Vaughan R.},
  date      = {1973-10-01},
  series    = {{{POPL}} '73},
  pages     = {41--51},
  publisher = {Association for Computing Machinery},
  location  = {New York, NY, USA},
  doi       = {10.1145/512927.512931},
  url       = {https://dl.acm.org/doi/10.1145/512927.512931},
  urldate   = {2025-02-07},
  isbn      = {978-1-4503-7349-4}
}

@article{remyEXTENSIONMLTYPE,
  title    = {{{EXTENSION OF ML TYPE SYSTEM WITH A SORTED EQUATIONAL THEORY ON TYPES}}},
  author   = {Remy, Didier},
  abstract = {We extend the ML language by allowing a sorted regular equational theory on types for which uni cation is decidable and unitary. We prove that the extension keeps principal typings and subject reduction. A new set of typing rules is proposed so that type generalization is simpler and more e cient. We consider typing problems as general uni cation problems, which we solve with a formalism of uni cands. Uni cands naturally deal with sharing between types and lead to a more e cient type inference algorithm. The use of uni cands also simpli es the proof of correctness of the algorithm by splitting it into more elementary steps.},
  langid   = {english}
}

@inproceedings{sabryContinuationpassingUsefulData1994,
  title     = {Is Continuation-Passing Useful for Data Flow Analysis?},
  booktitle = {Proceedings of the {{ACM SIGPLAN}} 1994 Conference on {{Programming}} Language Design and Implementation},
  author    = {Sabry, Amr and Felleisen, Matthias},
  date      = {1994-06-01},
  series    = {{{PLDI}} '94},
  pages     = {1--12},
  publisher = {Association for Computing Machinery},
  location  = {New York, NY, USA},
  doi       = {10.1145/178243.178244},
  url       = {https://dl.acm.org/doi/10.1145/178243.178244},
  urldate   = {2025-02-05},
  abstract  = {The widespread use of the continuation-passing style (CPS) transformation in compilers, optimizers, abstract interpreters, and partial evaluators reflects a common belief that the transformation has a positive effect on the analysis of programs. Investigations by Nielson [13] and Burn/Filho [5,6] support, to some degree, this belief with theoretical results. However, they do not pinpoint the source of increased abstract information and do not explain the observation of many people that continuation-passing confuses some conventional data flow analyses.To study the impact of the CPS transformation on program analysis, we derive three canonical data flow analyzers for the core of an applicative higher-order programming language. The first analyzer is based on a direct  semantics  of the language, the second on a continuation-semantics of the language, and the last on the direct semantics of CPS terms. All analyzers compute the control flow graph of the source program and hence our results apply to a large class of data flow analyses. A comparison of the information gathered by our analyzers establishes the following points:In view of these results, we argue that, in practice, a direct data flow analysis that relies on some amount of duplication would be as satisfactory as a CPS analysis.},
  isbn      = {978-0-89791-662-2}
}

@article{tolmachMLAdaStronglytyped1998,
  title        = {From {{ML}} to {{Ada}}: {{Strongly-typed}} Language Interoperability via Source Translation},
  shorttitle   = {From {{ML}} to {{Ada}}},
  author       = {Tolmach, Andrew and Oliva, Dino P.},
  date         = {1998-07},
  journaltitle = {Journal of Functional Programming},
  shortjournal = {J. Funct. Prog.},
  volume       = {8},
  number       = {4},
  pages        = {367--412},
  publisher    = {Cambridge University Press (CUP)},
  issn         = {0956-7968, 1469-7653},
  doi          = {10.1017/s0956796898003086},
  url          = {https://www.cambridge.org/core/product/identifier/S0956796898003086/type/journal_article},
  urldate      = {2025-07-16},
  abstract     = {We describe a system that supports source-level integration of ML-like functional language code with ANSI C or Ada83 code. The system works by translating the functional code into type-correct, ‘vanilla’ C or Ada; it offers simple, efficient, type-safe inter-operation between new functional code components and ‘legacy’ third-generation-language components. Our translator represents a novel synthesis of techniques including user-parameterized specification of primitive types and operators; removal of polymorphism by code specialization; removal of higher-order functions using closure datatypes and interpretation; and aggressive optimization of the resulting first-order code, which can be viewed as encoding the result of a closure analysis. Programs remain fully typed at every stage of the translation process, using only simple, standard type systems. Target code runs at speeds comparable to the output of current optimizing ML compilers, even though handicapped by a conservative garbage collector.},
  langid       = {english}
}

@online{Monomorphise,
  title   = {Monomorphise},
  url     = {http://www.mlton.org/Monomorphise},
  urldate = {2025-09-14}
}

@article{brandonBetterDefunctionalizationLambda2023a,
  title        = {Better {{Defunctionalization}} through {{Lambda Set Specialization}}},
  author       = {Brandon, William and Driscoll, Benjamin and Dai, Frank and Berkow, Wilson and Milano, Mae},
  date         = {2023-06-06},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume       = {7},
  pages        = {977--1000},
  issn         = {2475-1421},
  doi          = {10.1145/3591260},
  url          = {https://dl.acm.org/doi/10.1145/3591260},
  urldate      = {2025-09-27},
  abstract     = {WILLIAM BRANDON∗, Massachusetts Institute of Technology, USA BENJAMIN DRISCOLL∗, Stanford University, USA FRANK DAI, WILSON BERKOW, and MAE MILANO, University of California, Berkeley, USA Higher-order functions pose a challenge for both static program analyses and optimizing compilers. To simplify the analysis and compilation of languages with higher-order functions, a rich body of prior work has proposed a variety of defunctionalization techniques, which can eliminate higher-order functions from a program by transforming the program to a semantically-equivalent first-order representation. Several modern languages take this a step further, specializing higher-order functions with respect to the functions on which they operate, and in turn allowing compilers to generate more efficient code. However, existing specializing defunctionalization techniques restrict how function values may be used, forcing implementations to fall back on costly dynamic alternatives. We propose lambda set specialization (LSS), the first specializing defunctionalization technique which imposes no restrictions on how function values may be used. We formulate LSS in terms of a polymorphic type system which tracks the flow of function values through the program, and use this type system to recast specialization of higher-order functions with respect to their arguments as a form of type monomorphization. We show that our type system admits a simple and tractable type inference algorithm, and give a formalization and fully-mechanized proof in the Isabelle/HOL proof assistant showing soundness and completeness of the type inference algorithm with respect to the type system. To show the benefits of LSS, we evaluate its impact on the run time performance of code generated by the MLton compiler for Standard ML, the OCaml compiler, and the new Morphic functional programming language. We find that pre-processing with LSS achieves run time speedups of up to 6.85× under MLton, 3.45× for OCaml, and 78.93× for Morphic. CCS Concepts: • Software and its engineering → Polymorphism; Procedures, functions and subroutines.},
  issue        = {PLDI},
  langid       = {english}
}

@software{lebedaTomLebedaChroma_code2025,
  title    = {{{TomLebeda}}/Chroma\_code},
  author   = {Lebeda, Tomáš},
  date     = {2025-07-06T20:54:28Z},
  origdate = {2023-08-18T17:27:36Z},
  url      = {https://github.com/TomLebeda/chroma_code},
  urldate  = {2025-09-28},
  abstract = {Make beautiful colored code listings in LaTeX with the power of TreeSitter.},
  keywords = {latex,listings,syntax-highlighting,tree-sitter}
}

@online{GarbageCollector,
  title   = {A Garbage Collector for {{C}} and {{C}}++},
  url     = {https://www.hboehm.info/gc/},
  urldate = {2025-09-28},
}

@online{godboltCompilerExplorer,
  title = {Compiler {{Explorer}}},
  author = {Godbolt, Matt},
  url = {https://godbolt.org/},
  urldate = {2025-09-30},
}

@software{peterHyperfine2023,
  title = {Hyperfine},
  author = {Peter, David},
  date = {2023-03},
  origdate = {2018-01-13T15:49:54Z},
  url = {https://github.com/sharkdp/hyperfine},
  urldate = {2025-10-14},
  abstract = {A command-line benchmarking tool},
  version = {1.16.1}
}
